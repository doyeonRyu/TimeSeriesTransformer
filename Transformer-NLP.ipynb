{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEVxaRwW8B3A"
      },
      "source": [
        "# Attention is All You Need - NLP 처리 transformer 모델 기본 코드 구성 (Transformer 모듈로 코드 수정)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4sAcX2W8EcP"
      },
      "source": [
        "참고\n",
        "> https://medium.com/data-science/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb\n",
        "\n",
        "를 바탕으로 GPT와 구현함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnciZZgb8HNr"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d7LmZbV7-aj"
      },
      "outputs": [],
      "source": [
        "# 1. import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fwxsmJoP6Y4"
      },
      "source": [
        "### Preparing sample data (sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5Y1_aP8L3P4"
      },
      "outputs": [],
      "source": [
        "# 임의의 자연어 문장 데이터\n",
        "raw_sentences = [\n",
        "    \"The cat sat on the mat\",\n",
        "    \"The dog barked at the cat\",\n",
        "    \"The sun is shining brightly\",\n",
        "    \"The quick brown fox jumps over the lazy dog\",\n",
        "    \"Artificial intelligence is the future of technology\",\n",
        "    \"Deep learning models are powerful tools for data analysis\",\n",
        "    \"Natural language processing enables machines to understand human language\",\n",
        "    \"Transformers have revolutionized the field of machine translation\",\n",
        "    \"Recurrent neural networks are useful for sequential data\",\n",
        "    \"The weather today is sunny with a chance of rain\",\n",
        "]\n",
        "\n",
        "# 각 문장을 (입력, 출력) 쌍으로 구성\n",
        "# 입력은 문장의 단어들, 출력은 다음 단어\n",
        "# 예: \"The cat sat on the\" -> \"cat sat on the mat\"\n",
        "src_sentences = []\n",
        "tgt_sentences = []\n",
        "\n",
        "for sentence in raw_sentences:\n",
        "    words = sentence.strip().split()\n",
        "    if len(words) >= 3:\n",
        "        src_sentences.append(words[:-1])\n",
        "        tgt_sentences.append(words[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRlPXK6TL41P",
        "outputId": "b3355cf4-78c5-4cf7-d6ec-4358a9cb72b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'cat', 'sat', 'on', 'the']\n",
            "['cat', 'sat', 'on', 'the', 'mat']\n"
          ]
        }
      ],
      "source": [
        "print(src_sentences[0])\n",
        "print(tgt_sentences[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeEzXoFAQVX6"
      },
      "source": [
        "### Tokenize & Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94uY00JXL5Ms"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# 1. 문장 -> 단어 단위 토큰화\n",
        "def tokenize(sentences):\n",
        "    return sentence.lower().replace('.', '').split()\n",
        "\n",
        "# 2. (src, tgt) 문장 분리\n",
        "src_sentences = []\n",
        "tgt_sentences = []\n",
        "\n",
        "for sentence in raw_sentences:\n",
        "    tokens = tokenize(sentence)\n",
        "    if len(tokens) >= 3:\n",
        "        src_sentences.append(tokens[:-1]) # 입력: 끝 단어 제외\n",
        "        tgt_sentences.append(tokens[1:]) # 출력: 시작 단어 제외\n",
        "\n",
        "# 3. 전체 단어 수집 (단어 사전 생성)\n",
        "all_tokens = [tokens for sent in src_sentences + tgt_sentences for tokens in sent]\n",
        "token_freq = Counter(all_tokens)\n",
        "vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}  # 특수 토큰 포함\n",
        "\n",
        "for token in token_freq:\n",
        "    if token not in vocab:\n",
        "        vocab[token] = len(vocab)\n",
        "\n",
        "# 4. 인덱스 -> 단어 매핑도 저장\n",
        "inv_vocab = {idx: token for token, idx in vocab.items()}\n",
        "\n",
        "# 5. 문장 시퀀스를 정수 인덱스로 변환 (패딩 포함)\n",
        "def encode(tokens, vocab, max_len):\n",
        "    ids = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
        "    ids = [vocab['<sos>']] + ids + [vocab['<eos>']]  # 시작/종료 토큰 추가\n",
        "    if len(ids) < max_len:\n",
        "        ids += [vocab['<pad>']] * (max_len - len(ids))  # 패딩\n",
        "    else:\n",
        "        ids = ids[:max_len]\n",
        "    return ids\n",
        "\n",
        "# 6. 시퀀스 최대 길이 설정 (특수 토큰 포함)\n",
        "max_seq_length = 10\n",
        "\n",
        "src_encoded = [encode(sent, vocab, max_seq_length) for sent in src_sentences]\n",
        "tgt_encoded = [encode(sent, vocab, max_seq_length) for sent in tgt_sentences]\n",
        "\n",
        "# 7. 텐서 변환\n",
        "src_tensor = torch.tensor(src_encoded)\n",
        "tgt_tensor = torch.tensor(tgt_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkdGX6_zMB9q",
        "outputId": "7b6bd07a-0fa3-4985-fd6d-abb988cfa238"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "src_tensor.shape  # torch.Size([10, 10])  ← 10문장, 각 10단어 (패딩 포함)\n",
        "tgt_tensor.shape  # torch.Size([10, 10])\n",
        "\n",
        "# vocab = {\n",
        "#     '<pad>': 0,\n",
        "#     '<sos>': 1,\n",
        "#     '<eos>': 2,\n",
        "#     '<unk>': 3,\n",
        "#     'the': 4,\n",
        "#     'cat': 5,\n",
        "#     ...\n",
        "# }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUeDHMg28Vx0"
      },
      "source": [
        "### MultiHeadAttention & Position-wise Feed-Forward Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ecv-9z2C9pnT"
      },
      "source": [
        "PyTorch의 `nn.Transformer` 또는 `nn.TransformerEncoderLayer`/`nn.TransformerDecoderLayer`를 사용할 경우: **MultiHeadAttention, Position-wise Feed-Forward Networks** 구현 필요 x   \n",
        "1. `nn.Transformer`는 이미 내부에 모든 구성요소를 포함함\n",
        "  - `MultiHeadAttention` = `nn.MultiheadAttention`\n",
        "  - `PositionWiseFeedForward` = `nn.Linear -> ReLU -> nn.Linear`\n",
        "  - `Residual` + `LayerNorm` = 이미 각 sublayer 안에 포함\n",
        "\n",
        "2. `nn.TransformerEncoderLayer`, `nn.TransformerDecoderLayer`는 **Attention + FFN + LayerNorm** 구조를 기본으로 가짐\n",
        "  - 사용자가 직접 분리 구현할 필요없이 클래스를 불러서 layer stacking만 하면 됨\n",
        "\n",
        "3. 직접 구현은 학습 목적 또는 커스터마이징할 경우에만 필요함\n",
        "  - 예) Attention 타입을 바꾸거나, 구조를 변경하려는 경우"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vPrEebm_O-P"
      },
      "source": [
        "### Positional Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXYTE8a5HQrE"
      },
      "source": [
        "- 기존 코드와 거의 동일\n",
        "- 차이점: `dropout` 추가\n",
        "  - Transformer 모델에서 embedding + positional encoding 결과에 `dropout`을 적용하는 이유\n",
        "    1. 과적합 방지\n",
        "      - embedding + positional encoding은 모델의 첫 입력이자 모든 레이어를 거쳐 전달되는 정도의 출발점\n",
        "      - 이 첫 입력을 통해 overfitting 발생 가능성\n",
        "      - `dropout`으로 입력의 일부를 무작위로 제거해 일반화 성능 향상\n",
        "    2. 다른 레이어들과의 일관성\n",
        "      - Transformer의 모든 sub-layer ouput(`attention`, `feed-forward` 등)에는 `dropout` 적용됨\n",
        "      - positional encoding에도 `dropout`을 걸어주는 건 그 구조와 학습 방식의 일관성 유지에 도움\n",
        "- transformer에서 dropout 실행해줄 것으로 다시 제거함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHCU3bOetB_7"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    # d_model: 임베딩 차원, max_deq_length: 최대 시퀀스 길이\n",
        "    def __init__(self, d_model, max_seq_length):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # 전체 시퀀스 길이와 차원 수에 맞는 위치 벡터를 0으로 초기화\n",
        "        pe = torch.zeros(max_seq_length, d_model)\n",
        "\n",
        "        # position[0], [1], [2], ..., [max_seq_length-1] 형태로 위치 벡터 생성\n",
        "        # .unsqueeze(1)은 2D로 변환 (모양: [max_seq_length, 1])\n",
        "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # sin, cos의 주기를 다르게 해주는 인자\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "        # 짝수 인덱스는 sin, 홀수 인덱스는 cos을 사용\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # pe를 학습 파라미터는 아니지만 모델의 일부로 등록\n",
        "        # 학습 중에는 업데이트 되지 않지만 GPU 메모리에 저장되어 forward 시 사용됨\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))  # shape: (1, max_seq_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 입력 임베딩 x에 위치 인코딩을 더함\n",
        "        # self.pe[:, :x.size(1)]는 입력 길이에 맞는 위치 벡터만 사용\n",
        "        return x + self.pe[:, :x.size(1)] # x shape: (batch_size, seq_len, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUBjF2uhKABK"
      },
      "source": [
        "### EncoderLayer & DecoderLayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzVmENTpRXqW"
      },
      "source": [
        "- `nn.TransformerEncoderLayer`, `nn.TransformerDecoderLayer`로 구현 가능\n",
        "- EncoderLayer 포함 유소  \n",
        "  - MultiHeadAttention, LayerNorm, Dropout, PositionWiseFeedForward\n",
        "- DecoderLayer 포함 요소\n",
        "  - Masked MultiHeadAttention, Cross-Attention, LayerNorm, Dropout, PositionWiseFeedForward\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPxKKzkHSUrh"
      },
      "source": [
        "### TransformerModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ1B9oNxXXj6"
      },
      "source": [
        "- PositionalEncoding의 dropout 문제\n",
        "  - PositionalEncoding class: 위치 정보만 더해주는 역할\n",
        "  - TransformerModel forward: dropout 추가해줌\n",
        "    - `src = self.dropout(self.positional_encoding(self.encoder_embedding(src)))`\n",
        "    - tgt = `self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))`\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8KwTwgS5ioL"
      },
      "source": [
        "#### generate_mask() 함수 삭제함\n",
        "- 직접 구현한 transformer 구조의 마스크 형태와 다른 형식 필요\n",
        "- PyTorch의 `nn.Transformer` 계열 모듈: 세 종류의 마스크를 분리해서 받음\n",
        "- 따라서 역할별 마스크를 따로 제공   \n",
        "| 마스크 이름                 | Shape              | 역할                                                             |\n",
        "|----------------------------|--------------------|------------------------------------------------------------------|\n",
        "| `tgt_mask`                | (tgt_len, tgt_len) | 미래 차단 (no-peak mask), 디코더의 자기 회귀 형태 유지              |\n",
        "| `src_key_padding_mask`    | (batch, src_len)   | 소스 문장의 패딩 토큰 무시                                         |\n",
        "| `tgt_key_padding_mask`    | (batch, tgt_len)   | 타겟 문장의 패딩 토큰 무시                                         |\n",
        "| `memory_key_padding_mask` | (batch, src_len)   | 인코더 출력 마스킹 (일반적으로 `src_key_padding_mask`와 동일하게 사용) |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTplQ6absujK"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        # 소스, 타겟 임베딩\n",
        "        # 1. 소스 문장을 임베딩 벡터로 전환 (단어 ID -> d_model 차원 벡터)\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model) # == encoder_embedding\n",
        "        # 2. 타켓 문장을 임베딩 벡터로 변환\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model) # == decoder_embedding\n",
        "        # 3. 위치 정보를 임베딩에 추가\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        # 인코더 레이어와 전체 인코더\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=d_ff,\n",
        "            dropout=dropout,\n",
        "            activation='relu', # PositionWiseFeedForward 내부 활성화 함수 지정\n",
        "            batch_first=True # 입력 텐서의 shape 순서를 (batch, seq_len, d_model)로 고정\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # 디코더 레이어와 전체 디코더\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=d_ff,\n",
        "            dropout=dropout,\n",
        "            activation='relu', # PositionWiseFeedForward 내부 활성화 함수 지정\n",
        "            batch_first=True # 입력 텐서의 shape 순서를 (batch, seq_len, d_model)로 고정\n",
        "        )\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # 최종 출력 → 단어 분포\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size) # linear\n",
        "\n",
        "        # 드롭아웃\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None, memory_key_padding_mask=None, tgt_mask=None):\n",
        "        # 1. 임베딩 + 위치 인코딩\n",
        "        src_emb = self.dropout(self.positional_encoding(self.src_embedding(src)))  # (batch, seq, d_model)\n",
        "        tgt_emb = self.dropout(self.positional_encoding(self.tgt_embedding(tgt)))\n",
        "\n",
        "        # 2. 인코더\n",
        "        memory = self.encoder(src_emb, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # 3. 디코더\n",
        "        output = self.decoder(tgt_emb, memory,\n",
        "                              tgt_mask=tgt_mask,\n",
        "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                              memory_key_padding_mask=memory_key_padding_mask)\n",
        "\n",
        "        # 4. 최종 출력층\n",
        "        return self.fc_out(output)  # (batch, tgt_seq_len, vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Setting and Model Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. 하이퍼파라미터 설정 (vocab과 시퀀스 길이에 맞춤)\n",
        "src_vocab_size = len(vocab)       # 단어 사전 크기\n",
        "tgt_vocab_size = len(vocab)       # 동일하게 사용\n",
        "d_model = 512                     # 임베딩 차원\n",
        "num_heads = 8                     # Multi-head 수\n",
        "num_layers = 6                    # 인코더/디코더 레이어 수\n",
        "d_ff = 2048                       # FeedForward 차원\n",
        "max_seq_length = 10              # 우리가 encode할 때 사용한 길이\n",
        "dropout = 0.1                     # 드롭아웃 비율\n",
        "\n",
        "# 2. Transformer 모델 초기화\n",
        "model = TransformerModel(\n",
        "    src_vocab_size=src_vocab_size,\n",
        "    tgt_vocab_size=tgt_vocab_size,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    num_layers=num_layers,\n",
        "    d_ff=d_ff,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout\n",
        ")\n",
        "\n",
        "# 3. 영어 문장에서 생성된 실제 입력 데이터 사용\n",
        "src_data = src_tensor  # shape: (10, 10)\n",
        "tgt_data = tgt_tensor  # shape: (10, 10)\n",
        "batch_size = src_data.size(0)  # = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyDreY5bYox6"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDsClvk8p3_N",
        "outputId": "ea284826-5f5d-4182-9735-7e71bc13d3a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 4.2341\n",
            "Epoch 2, Loss: 3.9380\n",
            "Epoch 3, Loss: 3.9025\n",
            "Epoch 4, Loss: 3.7953\n",
            "Epoch 5, Loss: 3.6977\n",
            "Epoch 6, Loss: 3.5489\n",
            "Epoch 7, Loss: 3.4313\n",
            "Epoch 8, Loss: 3.2201\n",
            "Epoch 9, Loss: 2.8779\n",
            "Epoch 10, Loss: 2.7013\n"
          ]
        }
      ],
      "source": [
        "# 손실 함수 정의\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab['<pad>'])\n",
        "\n",
        "# 옵티마이저 정의\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# 모델 학습 모드로 전환\n",
        "model.train()\n",
        "\n",
        "# No-Peak 마스크 생성 함수 (디코더용 future masking)\n",
        "def generate_square_subsequent_mask(seq_len):\n",
        "    return torch.triu(torch.full((seq_len, seq_len), float('-inf')), diagonal=1)\n",
        "\n",
        "# 총 10 에포크 동안 학습\n",
        "for epoch in range(10):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 1. 입력 마스크 생성\n",
        "    seq_len = tgt_data.size(1)\n",
        "    tgt_mask = generate_square_subsequent_mask(seq_len - 1).to(tgt_data.device)\n",
        "\n",
        "    src_key_padding_mask = (src_data == vocab['<pad>'])          # (batch, src_len)\n",
        "    tgt_key_padding_mask = (tgt_data[:, :-1] == vocab['<pad>'])  # (batch, tgt_len - 1)\n",
        "\n",
        "    # 2. 디코더 입력/정답 분리\n",
        "    decoder_input = tgt_data[:, :-1]     # <sos> A B\n",
        "    target_output = tgt_data[:, 1:]      # A B <eos>\n",
        "\n",
        "    # 3. 모델 실행\n",
        "    output = model(\n",
        "        src=src_data,\n",
        "        tgt=decoder_input,\n",
        "        src_key_padding_mask=src_key_padding_mask,\n",
        "        tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "        memory_key_padding_mask=src_key_padding_mask,\n",
        "        tgt_mask=tgt_mask\n",
        "    )\n",
        "\n",
        "    # 4. 손실 계산 (출력: (batch, seq, vocab) → reshape)\n",
        "    loss = criterion(output.view(-1, len(vocab)), target_output.reshape(-1))\n",
        "\n",
        "    # 5. 역전파 및 업데이트\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNxd118DMw_w"
      },
      "source": [
        "### Transformer prediction -> Post-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuzyUj97NNGI",
        "outputId": "1e545938-7d53-4965-b7ac-f6ae48c67639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[예측 결과]\n",
            "[입력   1] the cat sat on the\n",
            "[정답   1] cat sat on the mat\n",
            "[예측   1] the the the the the the the the cat\n",
            "\n",
            "[입력   2] the dog barked at the\n",
            "[정답   2] dog barked at the cat\n",
            "[예측   2] the the the the the\n",
            "\n",
            "[입력   3] the sun is shining\n",
            "[정답   3] sun is shining brightly\n",
            "[예측   3] is is is is is is is is is\n",
            "\n",
            "[입력   4] the quick brown fox jumps over the lazy\n",
            "[정답   4] quick brown fox jumps over the lazy dog\n",
            "[예측   4] the dog dog the the the lazy dog\n",
            "\n",
            "[입력   5] artificial intelligence is the future of\n",
            "[정답   5] intelligence is the future of technology\n",
            "[예측   5] technology technology future technology technology technology technology technology future\n",
            "\n",
            "[입력   6] deep learning models are powerful tools for data\n",
            "[정답   6] learning models are powerful tools for data analysis\n",
            "[예측   6] are are are are for for for for data\n",
            "\n",
            "[입력   7] natural language processing enables machines to understand human\n",
            "[정답   7] language processing enables machines to understand human language\n",
            "[예측   7] language language language language language language language language language\n",
            "\n",
            "[입력   8] transformers have revolutionized the field of machine\n",
            "[정답   8] have revolutionized the field of machine translation\n",
            "[예측   8] machine machine of machine machine machine machine machine machine\n",
            "\n",
            "[입력   9] recurrent neural networks are useful for sequential\n",
            "[정답   9] neural networks are useful for sequential data\n",
            "[예측   9] for for for for for for for for for\n",
            "\n",
            "[입력   10] the weather today is sunny with a chance of\n",
            "[정답   10] weather today is sunny with a chance of rain\n",
            "[예측   10] is is is is is chance is chance is\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 1. softmax 확률 분포 계산\n",
        "probs = torch.softmax(output, dim=-1)  # 확률 분포\n",
        "\n",
        "# 2. 예측 인덱스 선택: argmax\n",
        "predicted_ids = output.argmax(dim=-1)  # shape: (batch, seq_len)\n",
        "\n",
        "# 3. 디코딩 함수 정의\n",
        "def decode_indices(indices, inv_vocab):\n",
        "    tokens = []\n",
        "    for idx in indices:\n",
        "        idx = idx.item()\n",
        "        if idx == vocab['<eos>']:\n",
        "            break\n",
        "        if idx != vocab['<pad>'] and idx != vocab['<sos>']:\n",
        "            tokens.append(inv_vocab.get(idx, '<unk>'))\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# 5. 배치 전체 예측 디코딩\n",
        "decoded_sentences = []\n",
        "for i in range(predicted_ids.size(0)):\n",
        "    decoded = decode_indices(predicted_ids[i], inv_vocab)\n",
        "    decoded_sentences.append(decoded)\n",
        "\n",
        "# 6. 예측 결과 비교 출력\n",
        "print(\"\\n[예측 결과]\")\n",
        "for i in range(len(decoded_sentences)):\n",
        "    input_text = decode_indices(src_data[i], inv_vocab)\n",
        "    target_text = decode_indices(tgt_data[i][1:], inv_vocab)  # 정답 시퀀스\n",
        "    print(f\"[입력   {i+1}] {input_text}\")\n",
        "    print(f\"[정답   {i+1}] {target_text}\")\n",
        "    print(f\"[예측   {i+1}] {decoded_sentences[i]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # 7. prediction -> post processing (정석 적용)\n",
        "# model.eval()  # 평가 모드로 전환\n",
        "\n",
        "# with torch.no_grad():  # 그래디언트 계산 생략 (속도 + 메모리 절약)\n",
        "#     output = model(\n",
        "#         src=src_data,\n",
        "#         tgt=tgt_data[:, :-1],\n",
        "#         src_key_padding_mask=(src_data == vocab['<pad>']),\n",
        "#         tgt_key_padding_mask=(tgt_data[:, :-1] == vocab['<pad>']),\n",
        "#         memory_key_padding_mask=(src_data == vocab['<pad>']),\n",
        "#         tgt_mask=generate_square_subsequent_mask(tgt_data.size(1) - 1).to(device)\n",
        "#     )\n",
        "\n",
        "# # 1. softmax 확률 분포 계산\n",
        "# probs = torch.softmax(output, dim=-1)  # 확률 분포\n",
        "\n",
        "# # 2. 예측 인덱스 선택: argmax\n",
        "# predicted_ids = output.argmax(dim=-1)  # shape: (batch, seq_len)\n",
        "\n",
        "# # 3. 디코딩 함수 정의\n",
        "# def decode_indices(indices, inv_vocab):\n",
        "#     tokens = []\n",
        "#     for idx in indices:\n",
        "#         idx = idx.item()\n",
        "#         if idx == vocab['<eos>']:\n",
        "#             break\n",
        "#         if idx != vocab['<pad>'] and idx != vocab['<sos>']:\n",
        "#             tokens.append(inv_vocab.get(idx, '<unk>'))\n",
        "#     return \" \".join(tokens)\n",
        "\n",
        "# # 5. 배치 전체 예측 디코딩\n",
        "# decoded_sentences = []\n",
        "# for i in range(predicted_ids.size(0)):\n",
        "#     decoded = decode_indices(predicted_ids[i], inv_vocab)\n",
        "#     decoded_sentences.append(decoded)\n",
        "\n",
        "# # 6. 예측 결과 비교 출력\n",
        "# print(\"\\n[예측 결과]\")\n",
        "# for i in range(len(decoded_sentences)):\n",
        "#     input_text = decode_indices(src_data[i], inv_vocab)\n",
        "#     target_text = decode_indices(tgt_data[i][1:], inv_vocab)  # 정답 시퀀스\n",
        "#     print(f\"[입력   {i+1}] {input_text}\")\n",
        "#     print(f\"[정답   {i+1}] {target_text}\")\n",
        "#     print(f\"[예측   {i+1}] {decoded_sentences[i]}\")\n",
        "#     print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtktPRn2Qndw"
      },
      "source": [
        "### END"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
